{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    \"\"\"\n",
    "    Performs linear regression on the data set X, y and plots the line of best fit\n",
    "    \"\"\"\n",
    "    # Convert X and y to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Calculate the slope and y-intercept of the line of best fit\n",
    "    m, b = np.polyfit(X.ravel(), y, 1)\n",
    "    \n",
    "    # Plot the data points and the line of best fit\n",
    "    plt.scatter(X, y)\n",
    "    plt.plot(X, m*X + b, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the slope and y-intercept of the line of best fit\n",
    "    return m, b\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Call the linear_regression function with the random data\n",
    "slope, intercept = linear_regression(X, y)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Call the linear_regression function with the random data\n",
    "slope, intercept = linear_regression(X, y)\n",
    "\n",
    "# Calculate the predicted values of y\n",
    "y_pred = slope*X + intercept\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = np.mean((y - y_pred)**2)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Call the linear_regression function with the random data\n",
    "slope, intercept = linear_regression(X, y)\n",
    "\n",
    "# Calculate the predicted values of y\n",
    "y_pred = slope*X + intercept\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "tss = np.sum((y - np.mean(y))**2)\n",
    "\n",
    "# Calculate the residual sum of squares\n",
    "rss = np.sum((y - y_pred)**2)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r_squared = 1 - (rss/tss)\n",
    "\n",
    "print(\"R-squared value:\", r_squared)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Call the linear_regression function with the random data\n",
    "slope, intercept = linear_regression(X, y)\n",
    "\n",
    "# Calculate the predicted values of y\n",
    "y_pred = slope*X + intercept\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "tss = np.sum((y - np.mean(y))**2)\n",
    "\n",
    "# Calculate the residual sum of squares\n",
    "rss = np.sum((y - y_pred)**2)\n",
    "\n",
    "# Calculate the R-squared value\n",
    "r_squared = 1 - (rss/tss)\n",
    "\n",
    "print(\"R-squared value:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Add a constant term to X for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Add a constant term to X for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Perform hypothesis testing on the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Add a constant term to X for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Perform residual analysis on the model\n",
    "residuals = model.resid\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(model.predict(), residuals)\n",
    "ax.axhline(y=0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate random data for a simple linear regression problem\n",
    "X = np.random.rand(100, 1)\n",
    "y = 2*X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Add a constant term to X for the intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Perform hypothesis testing on the coefficients\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc1 = nn.Linear(latent_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.fc5 = nn.Linear(1024, 3*32*32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.relu(self.fc1(z))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.tanh(self.fc5(x))\n",
    "        x = x.view(-1, 3, 32, 32)\n",
    "        return x\n",
    "\n",
    "# Define the discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(256*4*4, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.conv1(x))\n",
    "        x = self.leaky_relu(self.conv2(x))\n",
    "        x = self.leaky_relu(self.conv3(x))\n",
    "        x = self.leaky_relu(self.conv4(x))\n",
    "        x = x.view(-1, 256*4*4)\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transforms to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the flag images and apply the transforms\n",
    "\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a new image with a white background\n",
    "image = Image.new('RGB', (200, 100), color='white')\n",
    "\n",
    "# Draw a blue rectangle for the background of the flag\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.rectangle((0, 0, 200, 100/2), fill='blue')\n",
    "\n",
    "# Draw a white star in the center of the flag\n",
    "draw.polygon([(100, 25), (110, 50), (130, 50), (115, 60), (125, 85), (100, 70), (75, 85), (85, 60), (70, 50), (90, 50)], fill='white')\n",
    "\n",
    "# Save the image to a file\n",
    "image.save('flag.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root='flags.png', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision.datasets as datasets\n",
    "# import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Define the transforms to apply to the images\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((32, 32)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# # Load the flag images and apply the transforms\n",
    "# dataset = datasets.ImageFolder(root='path/to/flags', transform=transform)\n",
    "\n",
    "# # Define the generator and discriminator models\n",
    "# generator = Generator(latent_dim=100)\n",
    "# discriminator = Discriminator()\n",
    "\n",
    "# # Define the loss function and optimizer for the generator and discriminator\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "# optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# # Train the GAN model\n",
    "# batch_size = 128\n",
    "# num_epochs = 100\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, (real_images, _) in enumerate(dataloader):\n",
    "#         # Train the discriminator with real images\n",
    "#         real_images = real_images.to(device)\n",
    "#         labels_real = torch.ones(batch_size, 1).to(device)\n",
    "#         labels_fake = torch.zeros(batch_size, 1).to(device)\n",
    "#         discriminator.zero_grad()\n",
    "#         output_real = discriminator(real_images)\n",
    "#         loss_real = criterion(output_real, labels_real)\n",
    "#         loss_real.backward()\n",
    "\n",
    "#         # Train the discriminator with fake images\n",
    "#         noise = torch.randn(batch_size, 100).to(device)\n",
    "#         fake_images = generator(noise)\n",
    "#         output_fake = discriminator(fake_images.detach())\n",
    "#         loss_fake = criterion(output_fake, labels_fake)\n",
    "#         loss_fake.backward()\n",
    "\n",
    "#         # Update the discriminator parameters\n",
    "#         loss_D = loss_real + loss_fake\n",
    "#         optimizer_D.step()\n",
    "\n",
    "#         # Train the generator\n",
    "#         generator.zero_grad()\n",
    "#         output_fake = discriminator(fake_images)\n",
    "#         loss_G = criterion(output_fake, labels_real)\n",
    "#         loss_G.backward()\n",
    "\n",
    "#         # Update the generator parameters\n",
    "#         optimizer_G.step()\n",
    "\n",
    "#         # Print the loss every 100 batches\n",
    "#         if i % 100 == 0:\n",
    "#             print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Get historical data for FXIAX from Yahoo Finance\n",
    "ticker = yf.Ticker(\"MTCH\")\n",
    "data = ticker.history(period=\"max\")\n",
    "\n",
    "# Print the first few rows of the data\n",
    "print(data.tail())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the close of the data\n",
    "plt.plot(data['Close'])\n",
    "plt.title('MTCH Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Get historical data for FXIAX from Yahoo Finance\n",
    "ticker = yf.Ticker(\"META\")\n",
    "data = ticker.history(period=\"max\")\n",
    "\n",
    "# Print the first few rows of the data\n",
    "print(data.tail())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the close of the data\n",
    "plt.plot(data['Close'])\n",
    "plt.title('MTCH Close Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Daily and Cumulative Returns, CAPM\n",
    "\n",
    "# %% [markdown]\n",
    "# This post includes code and notes from [python for finance and trading algorithms udemy course](https://udemy.com/python-for-finance-and-trading-algorithms/) and [python for finance and trading algorithms udemy course notebooks](https://github.com/theoneandonlywoj/Python-for-Financial-Analysis-and-Algorithmic-Trading).\n",
    "\n",
    "# %%\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "import yfinance as yf\n",
    "data = yf.download(\"AAPL\", start=\"2017-01-01\", end=\"2017-04-30\")\n",
    "data\n",
    "\n",
    "# %%\n",
    "# import pandas_datareader as web\n",
    "\n",
    "# #web.get_data_fred('GS10')\n",
    "\n",
    "# import pandas_datareader as pdr\n",
    "# import datetime\n",
    "\n",
    "# # Get stock data for Apple from Yahoo Finance\n",
    "# start = datetime.datetime(2020, 1, 1)\n",
    "# end = datetime.datetime(2021, 1, 1)\n",
    "# df = pdr.get_data_yahoo('AAPL', start=start, end=end)\n",
    "\n",
    "# # Get stock data for Microsoft from Google Finance\n",
    "# start = datetime.datetime(2020, 1, 1)\n",
    "# end = datetime.datetime(2021, 1, 1)\n",
    "# df = pdr.get_data_google('MSFT', start=start, end=end)\n",
    "\n",
    "# # Get cryptocurrency data for Bitcoin from Coinbase\n",
    "# start = datetime.datetime(2020, 1, 1)\n",
    "# end = datetime.datetime(2021, 1, 1)\n",
    "# df = pdr.get_data_coinbase('BTC-USD', start=start, end=end)\n",
    "\n",
    "# # Get economic data for US GDP from FRED\n",
    "# start = datetime.datetime(2020, 1, 1)\n",
    "# end = datetime.datetime(2021, 1, 1)\n",
    "# df = pdr.get_data_fred('GDP', start=start, end=end)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "FXAIX_stock = yf.download(\"FXAIX\", start=\"2020-09-01\", end=\"2023-05-01\")\n",
    "\n",
    "FXAIX_stock.head()\n",
    "MTCH_stock = yf.download('MTCH', start=\"2022-06-01\", end=\"2023-05-01\")\n",
    "\n",
    "MTCH_stock.head()\n",
    "\n",
    "META_stock = yf.download('META', start=\"2022-06-01\", end=\"2023-05-01\")\n",
    "META_stock.head()\n",
    "\n",
    "\n",
    "FSMAX_stock = yf.download('FSMAX', start=\"2020-09-01\", end=\"2023-05-01\")\n",
    "FSMAX_stock.head()\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# %%\n",
    "#stocks\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Compare Cumulative Return\n",
    "\n",
    "# %%\n",
    "FXAIX_stock['Cumulative'] = FXAIX_stock['Close']/FXAIX_stock['Close'].iloc[0]\n",
    "MTCH_stock['Cumulative'] = MTCH_stock['Close']/MTCH_stock['Close'].iloc[0]\n",
    "META_stock['Cumulative'] = META_stock['Close']/META_stock['Close'].iloc[0]\n",
    "FSMAX_stock['Cumulative'] = FSMAX_stock['Close']/FSMAX_stock['Close'].iloc[0]\n",
    "\n",
    "# %%\n",
    "FXAIX_stock['Cumulative'].plot(label='FXAIX_stock',figsize=(10,8))\n",
    "MTCH_stock['Cumulative'].plot(label='MTCH_stock',figsize=(10,8))\n",
    "META_stock['Cumulative'].plot(label='META_stock',figsize=(10,8))\n",
    "#FSMAX_stock['Cumulative'].plot(label='FSMAX_stock',figsize=(10,8))\n",
    "plt.legend()\n",
    "plt.title('Cumulative Return')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Get Daily Return\n",
    "\n",
    "# %%\n",
    "META_stock['Daily Return'] = META_stock['Close'].pct_change(1)\n",
    "MTCH_stock['Daily Return'] = MTCH_stock['Close'].pct_change(1)\n",
    "FXAIX_stock['Daily Return'] = FXAIX_stock['Close'].pct_change(1)\n",
    "\n",
    "\n",
    "# %%\n",
    "META_stock['Daily Return']\n",
    "\n",
    "# %%\n",
    "plt.scatter(META_stock['Daily Return'],MTCH_stock['Daily Return'],alpha=0.3)\n",
    "\n",
    "# %%\n",
    "MTCH_stock['Daily Return'].hist(bins=100)\n",
    "\n",
    "# %%\n",
    "FXAIX_stock['Daily Return'].hist(bins=100)\n",
    "\n",
    "# %%\n",
    "beta,alpha,r_value,p_value,std_err = stats.linregress(MTCH_stock['Daily Return'].iloc[1:],META_stock['Daily Return'].iloc[1:])\n",
    "\n",
    "# %%\n",
    "beta\n",
    "\n",
    "# %%\n",
    "alpha\n",
    "\n",
    "# %%\n",
    "r_value\n",
    "\n",
    "# %%\n",
    "FXAIX_stock['Daily Return'].head()\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "\n",
    "# %%\n",
    "noise = np.random.normal(0,0.001,len(FXAIX_stock['Daily Return'].iloc[1:]))\n",
    "\n",
    "# %%\n",
    "#noise\n",
    "\n",
    "# %%\n",
    "FXAIX_stock['Daily Return'].iloc[1:] + noise\n",
    "\n",
    "# %%\n",
    "beta,alpha,r_value,p_value,std_err = stats.linregress(FXAIX_stock['Daily Return'].iloc[1:]+noise,FXAIX_stock['Daily Return'].iloc[1:])\n",
    "\n",
    "# %%\n",
    "beta\n",
    "\n",
    "# %%\n",
    "alpha\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np\n",
    "\n",
    "# Define the Stan model\n",
    "model_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  vector[N] y;\n",
    "}\n",
    "parameters {\n",
    "  real mu;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the model\n",
    "model = pystan.StanModel(model_code=model_code)\n",
    "\n",
    "# Generate some example data\n",
    "N = 100\n",
    "y = np.random.normal(0, 1, N)\n",
    "\n",
    "# Fit the model to the data\n",
    "fit = model.sampling(data={\"N\": N, \"y\": y})\n",
    "\n",
    "# Extract the posterior samples of the parameters\n",
    "mu_samples = fit.extract(\"mu\")[\"mu\"]\n",
    "sigma_samples = fit.extract(\"sigma\")[\"sigma\"]\n",
    "\n",
    "# Compute the forecast for the next 10 time steps\n",
    "forecast = np.random.normal(mu_samples[-1], sigma_samples[-1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Stan model\n",
    "model_code = \"\"\"\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "parameters {\n",
    "  real alpha;\n",
    "  real beta;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  y ~ normal(alpha + beta * x, sigma);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Compile the model\n",
    "model = pystan.StanModel(model_code=model_code)\n",
    "\n",
    "# Generate some example data\n",
    "N = 100\n",
    "x = np.random.normal(0, 1, N)\n",
    "y = 2 * x + np.random.normal(0, 1, N)\n",
    "\n",
    "# Fit the model to the data\n",
    "fit = model.sampling(data={\"N\": N, \"x\": x, \"y\": y})\n",
    "\n",
    "# Extract the posterior samples of the parameters\n",
    "alpha_samples = fit.extract(\"alpha\")[\"alpha\"]\n",
    "beta_samples = fit.extract(\"beta\")[\"beta\"]\n",
    "sigma_samples = fit.extract(\"sigma\")[\"sigma\"]\n",
    "\n",
    "# Plot the posterior distributions of the parameters\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].hist(alpha_samples, bins=30)\n",
    "axes[0].set_title(\"alpha\")\n",
    "axes[1].hist(beta_samples, bins=30)\n",
    "axes[1].set_title(\"beta\")\n",
    "axes[2].hist(sigma_samples, bins=30)\n",
    "axes[2].set_title(\"sigma\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
